# -*- coding: utf-8 -*-
"""Untitled27.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1mrdJ7eEhqNMwsvyAs1K_oBLYh-VEBg_7
"""

import pandas as pd
from imblearn.over_sampling import SMOTE
from sklearn.model_selection import train_test_split

# Read the dataset
df = pd.read_csv('scaled_X_features.csv')

# Separate the features (X) and target variable (y)
X = df.drop('learning_style', axis=1)
y = df['learning_style']


# Create an instance of the SMOTE class
smote = SMOTE()

# Apply SMOTE on the entire dataset
X_resampled, y_resampled = smote.fit_resample(X, y)

# Split the data into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.3, random_state=42)



# Print the balanced class distribution
print('Original class distribution:', y.value_counts())
print('Resampled class distribution:', y_resampled.value_counts())

from sklearn.ensemble import VotingClassifier
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score

# Define the parameter settings for SVM
svm_params = {

    'C': 100, 'gamma': 1, 'kernel': 'linear','class_weight': None
}

# Create the SVM classifier with the specified parameters
svm_classifier = SVC(**svm_params)

# Define the parameter settings for Random Forest
rf_params = {
    'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 300,'random_state':0
}

# Create the Random Forest classifier with the specified parameters
rf_classifier = RandomForestClassifier(**rf_params)

# Create the voting classifier that combines the predictions of the two models
voting_classifier = VotingClassifier(
    estimators=[('svm', svm_classifier), ('rf', rf_classifier)],
    voting='hard'  # or 'soft' for probabilistic voting
)

# Train the voting classifier on your training data
voting_classifier.fit(X_train, y_train)  # Replace X_train and y_train with your actual training data

# Make predictions on the test data using the voting classifier
y_pred = voting_classifier.predict(X_test)  # Replace X_test with your actual test data

# Calculate the accuracy of the ensemble model
accuracy = accuracy_score(y_test, y_pred)  # Replace y_test with your actual test labels

print("Ensemble Model Accuracy:", accuracy)

from sklearn.ensemble import RandomForestClassifier


from sklearn.metrics import confusion_matrix, accuracy_score
y_pred2 = voting_classifier.predict(X_test)
cm = confusion_matrix(y_test, y_pred2)
print(cm)
accuracy_score(y_test, y_pred2)

from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay, f1_score

pred_en=voting_classifier.predict(X_test)
score_en=accuracy_score(y_test,y_pred2)
f1_en = f1_score(y_pred2, y_test, average="weighted")

print('Accuracy of en',score_en)
print('F1 score of en',f1_en)
print("\n")

cm = confusion_matrix(y_test, pred_en, labels=voting_classifier.classes_)
disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=voting_classifier.classes_)
disp.plot()

from sklearn.model_selection import cross_val_score





# Perform cross-validation
cv_scores = cross_val_score(voting_classifier, X_train, y_train, cv=5)

# Print the accuracy scores for each fold
print("Cross-validation scores:", cv_scores)

# Compute the mean accuracy across all folds
mean_accuracy = cv_scores.mean()
print("Mean accuracy:", mean_accuracy)

print("Accuracy: {:.2f} %".format(cv_scores.mean()*100))
print("Standard Deviation: {:.2f} %".format(cv_scores.std()*100))

from sklearn.metrics import classification_report

# Assuming you have predicted labels stored in `y_pred` and true labels stored in `y_true`
print(classification_report(y_test, y_pred2, zero_division=0))

import numpy as np

# Assuming you have a trained model named 'model'

# Input features as a single list
input_features = [0.1	,0.35	,0.1	,0.6	,0.1	,0.5	,0.916666667	,0.75,	0.794117647	,0.635555556	,0.166666667	,0.5	,0.266666667	,0.846666667	,0	,0.072	,0.28]

# Convert the input features to a NumPy array and reshape it to match the model's input shape
input_features = np.array(input_features).reshape(1, -1)

# Make predictions on the input features
prediction = voting_classifier.predict(input_features)

# Print the predicted target label
print("Predicted target label:", prediction[0])

import numpy as np

# Assuming you have already trained and saved your classifier as 'classifier.pkl'
import joblib

# Load the pickled model
classifier = joblib.load('model.pkl')

# Define the names of your input features
feature_names = ['Amount of time spent by learners interacting with images', 'Amount of time spent on video related materials', 'Amount of time spent on text based material', 'Amount of time spent on audio related materials', 'complexity or depth of the learning material', 'Frequency of PowerPoint usage', 'Concrete contents', 'Performance or achievement of the learner ', 'Number of correctly answered standard questions','Number of messages or posts posted by the learner','Time or duration spent by the learner in solving exercises','Number of group discussions','Number of lessons of learning objectives skipped','Number of times the learner utilized the Next button','Amount of Time Spent in sessions',' Number of questions on topics','Number of questions or queries posed by the learner']

# Get input feature values from the user
input_features = []
for i in range(len(feature_names)):
    value = float(input(f"Enter value for {feature_names[i]}: "))
    input_features.append(value)

# Convert input features to a numpy array
input_features = np.array(input_features).reshape(1, -1)



target_label = classifier.predict(input_features)

# Create a dictionary to map the numeric labels to their corresponding labels
label_mapping = {0: 'Processing', 1: 'Understanding', 2: 'Input', 3: 'Perception'}

# Print the predicted target label with its corresponding label
predicted_label = label_mapping[target_label[0]]
print("Predicted target label:", predicted_label)

import numpy as np
from sklearn.preprocessing import MinMaxScaler
import joblib

# Load the pickled model
classifier = joblib.load('model.pkl')

# Define the names of your input features
feature_names = ['Amount of time spent by learners interacting with images', 'Amount of time spent on video related materials', 'Amount of time spent on text based material', 'Amount of time spent on audio related materials', 'complexity or depth of the learning material', 'Frequency of PowerPoint usage', 'Concrete contents', 'Performance or achievement of the learner ', 'Number of correctly answered standard questions','Number of messages or posts posted by the learner','Time or duration spent by the learner in solving exercises','Number of group discussions','Number of lessons of learning objectives skipped','Number of times the learner utilized the Next button','Amount of Time Spent in sessions',' Number of questions on topics','Number of questions or queries posed by the learner']

# Get input feature values from the user
input_features = []
for i in range(len(feature_names)):
    value = float(input(f"Enter value for {feature_names[i]}: "))
    input_features.append(value)

# Convert input features to a numpy array
input_features = np.array(input_features).reshape(1, -1)

# Scale the input features using MinMaxScaler
scaler = MinMaxScaler()
scaled_input_features = scaler.fit_transform(input_features)

# Predict the target label for the scaled input features
target_label = classifier.predict(scaled_input_features)

# Create a dictionary to map the numeric labels to their corresponding labels
label_mapping = {0: 'Processing', 1: 'Understanding', 2: 'Input', 3: 'Perception'}

# Print the predicted target label with its corresponding label
predicted_label = label_mapping[target_label[0]]
print("Predicted target label:", predicted_label)

import numpy as np
import joblib
from sklearn.preprocessing import MinMaxScaler

# Load the pickled model
classifier = joblib.load('model.pkl')

# Define the names of your input features
feature_names = ['Amount of time spent by learners interacting with images', 'Amount of time spent on video related materials', 'Amount of time spent on text based material', 'Amount of time spent on audio related materials', 'complexity or depth of the learning material', 'Frequency of PowerPoint usage', 'Concrete contents', 'Performance or achievement of the learner ', 'Number of correctly answered standard questions','Number of messages or posts posted by the learner','Time or duration spent by the learner in solving exercises','Number of group discussions','Number of lessons of learning objectives skipped','Number of times the learner utilized the Next button','Amount of Time Spent in sessions',' Number of questions on topics','Number of questions or queries posed by the learner']

# Get input feature values from the user
input_features = []
for i in range(len(feature_names)):
    value = float(input(f"Enter value for {feature_names[i]}: "))
    input_features.append(value)

# Convert input features to a numpy array
input_features = np.array(input_features).reshape(1, -1)

# Load the scaler
scaler = MinMaxScaler()

# Fit the scaler on the X_train dataset
scaler.fit(X_train)

# Scale the input features
scaled_input_features = scaler.transform(input_features)

# Predict the target label for the scaled input features
target_label = classifier.predict(scaled_input_features)

# Create a dictionary to map the numeric labels to their corresponding labels
label_mapping = {0: 'Processing', 1: 'Understanding', 2: 'Input', 3: 'Perception'}

# Print the predicted target label with its corresponding label
predicted_label = label_mapping[target_label[0]]
print("Predicted target label:", predicted_label)

from sklearn.svm import SVC
import numpy as np
import matplotlib.pyplot as plt

# Train the SVM classifier
model = SVC(C= 100, gamma= 1, kernel= 'linear',class_weight=None)
 #'C': 100, 'gamma': 1, 'kernel': 'rbf','class_weight': None
model.fit(X_train, y_train)

# Get the absolute magnitudes of the coefficients for each class
coefficients = np.abs(model.coef_)
class_names = model.classes_

# Plot the coefficients for each class
plt.figure(figsize=(10, 6))
for i, class_name in enumerate(class_names):
    sorted_indices = coefficients[i].argsort()[::-1]
    sorted_coefficients = coefficients[i][sorted_indices]
    feature_names = X.columns[sorted_indices]
    plt.bar(feature_names, sorted_coefficients, label=f"Class {class_name}")

plt.xticks(rotation=90)
plt.xlabel('Features')
plt.ylabel('Magnitude')
plt.title('SVM Coefficient Magnitudes')
plt.legend()
plt.show()

import pandas as pd
from imblearn.over_sampling import SMOTE
from sklearn.model_selection import train_test_split

# Read the dataset
df = pd.read_csv('scaled_X_features.csv')

# Separate the features (X) and target variable (y)
X = df.drop('learning_style', axis=1)
y = df['learning_style']






# Split the data into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)



import numpy as np
import joblib
from sklearn.preprocessing import MinMaxScaler

# Load the pickled model
classifier = joblib.load('model.pkl')

# Define the names of your input features
feature_names = ['Amount of time spent by learners interacting with images', 'Amount of time spent on video related materials', 'Amount of time spent on text based material', 'Amount of time spent on audio related materials', 'complexity or depth of the learning material', 'Frequency of PowerPoint usage', 'Concrete contents', 'Performance or achievement of the learner ', 'Number of correctly answered standard questions','Number of messages or posts posted by the learner','Time or duration spent by the learner in solving exercises','Number of group discussions','Number of lessons of learning objectives skipped','Number of times the learner utilized the Next button','Amount of Time Spent in sessions',' Number of questions on topics','Number of questions or queries posed by the learner']

# Get input feature values from the user
input_features = []
for i in range(len(feature_names)):
    value = float(input(f"Enter value for {feature_names[i]}: "))
    input_features.append(value)

# Convert input features to a numpy array
input_features = np.array(input_features).reshape(1, -1)

# Load the scaler
scaler = MinMaxScaler()

# Fit the scaler on the X_train dataset
scaler.fit(X_train)

# Scale the input features
scaled_input_features = scaler.transform(input_features)

# Predict the target label for the scaled input features
target_label = classifier.predict(scaled_input_features)

# Create a dictionary to map the numeric labels to their corresponding labels
label_mapping = {0: 'Processing', 1: 'Understanding', 2: 'Input', 3: 'Perception'}

# Print the predicted target label with its corresponding label
predicted_label = label_mapping[target_label[0]]
print("Predicted target label:", predicted_label)